{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1edb5e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parvez/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/parvez/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import scipy.spatial.distance \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils \n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6cb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb23e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parvez/Dataset/ModelNet40_dataset/ModelNet40\n"
     ]
    }
   ],
   "source": [
    "path=os.path.join(\"/home/parvez\",\"Dataset/ModelNet40_dataset/ModelNet40\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cb398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders=[dir for dir in sorted(os.listdir(path))]\n",
    "classes={folder:i for i, folder in enumerate(folders)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1a1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off(file):\n",
    "    off_header = file.readline().strip()\n",
    "    if 'OFF' == off_header:\n",
    "        n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "    else:\n",
    "        n_verts, n_faces, __ = tuple([int(s) for s in off_header[3:].split(' ')])\n",
    "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    return verts, faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa0b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'bed/train/bed_0001.off'),'r') as f:\n",
    "    verts, faces=read_off(f)\n",
    "      \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9c74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,k=np.array(faces).T\n",
    "x,y,z=np.array(verts).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172f38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointSampler(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size,int)\n",
    "        self.output_size=output_size\n",
    "        \n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        side_a=np.linalg.norm(pt1-pt2)\n",
    "        side_b=np.linalg.norm(pt2-pt3)\n",
    "        side_c=np.linalg.norm(pt3-pt1)\n",
    "        s=0.5*(side_a+side_b+side_c)\n",
    "        return max(s*(s-side_a)*(s-side_b)*(s-side_c),0)**0.5\n",
    "    \n",
    "    def sample_point(self, pt1,pt2,pt3):\n",
    "        s,t=sorted([random.random(), random.random()])\n",
    "        f=lambda i: s*pt1[i]+(t-s)*pt2[i]+(1-t)*pt3[i]\n",
    "        return (f(0), f(1), f(2))\n",
    "    \n",
    "    def __call__(self, mesh):\n",
    "        verts, faces=mesh\n",
    "        verts=np.array(verts)\n",
    "        areas=np.zeros((len(faces)))\n",
    "        for i in range(len(areas)):\n",
    "            areas[i]=(self.triangle_area(verts[faces[i][0]],\n",
    "                                       verts[faces[i][1]],\n",
    "                                       verts[faces[i][2]]))\n",
    "            \n",
    "        sampled_faces=(random.choices(faces,\n",
    "                                     weights=areas,\n",
    "                                     cum_weights=None,\n",
    "                                     k=self.output_size))\n",
    "        \n",
    "        sampled_points=np.zeros((self.output_size, 3))\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i]=(self.sample_point(verts[sampled_faces[i][0]],\n",
    "                                                verts[sampled_faces[i][1]],\n",
    "                                                verts[sampled_faces[i][2]]))\n",
    "            \n",
    "        return sampled_points\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a68fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud=PointSampler(3000)((verts, faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522d29b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pointcloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0130fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        norm_pointcloud=pointcloud -  np.mean(pointcloud, axis=0)\n",
    "        norm_pointcloud /=np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "        \n",
    "        return norm_pointcloud\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c287e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pointcloud = Normalize()(pointcloud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242ae61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        return torch.from_numpy(pointcloud)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61543ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "        PointSampler(1024),\n",
    "        Normalize(),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41aed748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self,root_dir, valid=False, folder='train', transform=default_transforms()):\n",
    "        self.root_dir=root_dir\n",
    "        folders=[dir for dir in sorted(os.listdir(root_dir))]\n",
    "        self.classes={folder:i for i, folder in enumerate(folders)}\n",
    "        self.transforms=transform if not valid else default_transforms()\n",
    "        self.valid=valid\n",
    "        self.files=[]\n",
    "        for category in self.classes.keys():\n",
    "            new_dir=os.path.join(root_dir, category, folder)\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):\n",
    "                    sample={}\n",
    "                    sample['pcd_path']=os.path.join(new_dir, file)\n",
    "                    sample['category']=category\n",
    "                    self.files.append(sample)\n",
    "                    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    \n",
    "    def __preproc__(self, file):\n",
    "        verts, faces=read_off(file)\n",
    "        if self.transforms:\n",
    "            pointcloud=self.transforms((verts, faces))\n",
    "        \n",
    "        return pointcloud \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path=self.files[idx]['pcd_path']\n",
    "        category=self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud=self.__preproc__(f)\n",
    "        return {'pointcloud' : pointcloud,\n",
    "                'category' : self.classes[category]}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1290cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=PointCloudData(path)\n",
    "valid_ds=PointCloudData(path, valid=True, folder='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d9ca02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader=DataLoader(dataset=valid_ds, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e1898e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'num_points':1024,\n",
    "       'batch_size':11,\n",
    "       'use_normals':False,\n",
    "       'optimizer':'RangerVA',\n",
    "       'lr':0.001,\n",
    "       'decay_rate':1e-06,\n",
    "       'epochs':500,\n",
    "       'num_classes':40,\n",
    "       'dropout':0.4,\n",
    "       'M':4,\n",
    "       'K':64,\n",
    "       'd_m':512\n",
    "       }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f5386c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "    def forward(self,input1, input2):\n",
    "        _,_,D=input1.shape\n",
    "        \n",
    "        Q=input1\n",
    "        K=input2\n",
    "        V=input1\n",
    "        \n",
    "        attn_weights=torch.bmm(Q, K.transpose(1,2))/math.sqrt(D)\n",
    "        \n",
    "        feature=torch.bmm(attn_weights, V)\n",
    "        \n",
    "        return feature\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fccccdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        \n",
    "        self.fc1=nn.Linear(3,64)\n",
    "        self.fc2=nn.Linear(64,128)\n",
    "        self.fc3=nn.Linear(128,256)\n",
    "        \n",
    "        self.attention=Attention()\n",
    "        \n",
    "        self.fc4=nn.Linear(256,128)\n",
    "        self.fc5=nn.Linear(128,64)\n",
    "        self.fc6=nn.Linear(64,40)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        self.softmax=nn.Softmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        input_ =input\n",
    "       \n",
    "        x=F.relu(self.fc1(input))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        \n",
    "        x= self.attention(x,x)\n",
    "        \n",
    "        x=F.relu(self.fc4(x))\n",
    "        x=F.relu(self.fc5(x))\n",
    "        x=self.fc6(x)\n",
    "        \n",
    "        x=torch.max(x, 1)[0]\n",
    "        x=torch.unsqueeze(x,1)\n",
    "        \n",
    "        \n",
    "        output=self.softmax(x)\n",
    "        \n",
    "        return output \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98613997",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ebfed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=3, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (attention): Attention()\n",
       "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc6): Linear(in_features=64, out_features=40, bias=True)\n",
       "  (softmax): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Model()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43ce715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97f11c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader,val_loader=None,epoch=1):\n",
    "    for epoch in range(epoch):\n",
    "        running_loss=0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels=data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs=model(inputs)\n",
    "            outputs=torch.squeeze(outputs)\n",
    "            \n",
    "            \n",
    "            loss=criterion(outputs,labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss+=loss.item()\n",
    "            \n",
    "            print(\"loss {} of batch {}: \".format(loss.item(),i))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac685578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.668440103530884 of batch 0: \n",
      "loss 3.730940103530884 of batch 1: \n",
      "loss 3.637190103530884 of batch 2: \n",
      "loss 3.637190103530884 of batch 3: \n",
      "loss 3.637190103530884 of batch 4: \n",
      "loss 3.637190103530884 of batch 5: \n",
      "loss 3.699690103530884 of batch 6: \n",
      "loss 3.449690103530884 of batch 7: \n",
      "loss 3.574690103530884 of batch 8: \n",
      "loss 3.699690103530884 of batch 9: \n",
      "loss 3.574690103530884 of batch 10: \n",
      "loss 3.637190103530884 of batch 11: \n",
      "loss 3.637190103530884 of batch 12: \n",
      "loss 3.574690103530884 of batch 13: \n",
      "loss 3.543440103530884 of batch 14: \n",
      "loss 3.637190103530884 of batch 15: \n",
      "loss 3.668440103530884 of batch 16: \n",
      "loss 3.730940103530884 of batch 17: \n",
      "loss 3.668440103530884 of batch 18: \n",
      "loss 3.574690103530884 of batch 19: \n",
      "loss 3.480940103530884 of batch 20: \n",
      "loss 3.730940103530884 of batch 21: \n",
      "loss 3.730940103530884 of batch 22: \n",
      "loss 3.668440103530884 of batch 23: \n",
      "loss 3.574690103530884 of batch 24: \n",
      "loss 3.605940103530884 of batch 25: \n",
      "loss 3.605940103530884 of batch 26: \n",
      "loss 3.668440103530884 of batch 27: \n",
      "loss 3.637190103530884 of batch 28: \n",
      "loss 3.637190103530884 of batch 29: \n",
      "loss 3.574690103530884 of batch 30: \n",
      "loss 3.668440103530884 of batch 31: \n",
      "loss 3.637190103530884 of batch 32: \n",
      "loss 3.605940103530884 of batch 33: \n",
      "loss 3.668440103530884 of batch 34: \n",
      "loss 3.699690103530884 of batch 35: \n",
      "loss 3.668440103530884 of batch 36: \n",
      "loss 3.574690103530884 of batch 37: \n",
      "loss 3.637190103530884 of batch 38: \n",
      "loss 3.668440103530884 of batch 39: \n",
      "loss 3.699690103530884 of batch 40: \n",
      "loss 3.637190103530884 of batch 41: \n",
      "loss 3.637190103530884 of batch 42: \n",
      "loss 3.637190103530884 of batch 43: \n",
      "loss 3.605940103530884 of batch 44: \n",
      "loss 3.668440103530884 of batch 45: \n",
      "loss 3.605940103530884 of batch 46: \n",
      "loss 3.699690103530884 of batch 47: \n",
      "loss 3.668440103530884 of batch 48: \n",
      "loss 3.637190103530884 of batch 49: \n",
      "loss 3.730940103530884 of batch 50: \n",
      "loss 3.574690103530884 of batch 51: \n",
      "loss 3.574690103530884 of batch 52: \n",
      "loss 3.543440103530884 of batch 53: \n",
      "loss 3.730940103530884 of batch 54: \n",
      "loss 3.543440103530884 of batch 55: \n",
      "loss 3.637190103530884 of batch 56: \n",
      "loss 3.605940103530884 of batch 57: \n",
      "loss 3.699690103530884 of batch 58: \n",
      "loss 3.637190103530884 of batch 59: \n",
      "loss 3.574690103530884 of batch 60: \n",
      "loss 3.637190103530884 of batch 61: \n",
      "loss 3.668440103530884 of batch 62: \n",
      "loss 3.574690103530884 of batch 63: \n",
      "loss 3.637190103530884 of batch 64: \n",
      "loss 3.668440103530884 of batch 65: \n",
      "loss 3.637190103530884 of batch 66: \n",
      "loss 3.605940103530884 of batch 67: \n",
      "loss 3.637190103530884 of batch 68: \n",
      "loss 3.699690103530884 of batch 69: \n",
      "loss 3.543440103530884 of batch 70: \n",
      "loss 3.637190103530884 of batch 71: \n",
      "loss 3.668440103530884 of batch 72: \n",
      "loss 3.668440103530884 of batch 73: \n",
      "loss 3.699690103530884 of batch 74: \n",
      "loss 3.668440103530884 of batch 75: \n",
      "loss 3.668440103530884 of batch 76: \n",
      "loss 3.543440103530884 of batch 77: \n",
      "loss 3.605940103530884 of batch 78: \n",
      "loss 3.668440103530884 of batch 79: \n",
      "loss 3.543440103530884 of batch 80: \n",
      "loss 3.605940103530884 of batch 81: \n",
      "loss 3.637190103530884 of batch 82: \n",
      "loss 3.637190103530884 of batch 83: \n",
      "loss 3.512190103530884 of batch 84: \n",
      "loss 3.637190103530884 of batch 85: \n",
      "loss 3.543440103530884 of batch 86: \n",
      "loss 3.543440103530884 of batch 87: \n",
      "loss 3.699690103530884 of batch 88: \n",
      "loss 3.637190103530884 of batch 89: \n",
      "loss 3.730940103530884 of batch 90: \n",
      "loss 3.637190103530884 of batch 91: \n",
      "loss 3.637190103530884 of batch 92: \n",
      "loss 3.574690103530884 of batch 93: \n",
      "loss 3.668440103530884 of batch 94: \n",
      "loss 3.574690103530884 of batch 95: \n",
      "loss 3.699690103530884 of batch 96: \n",
      "loss 3.668440103530884 of batch 97: \n",
      "loss 3.668440103530884 of batch 98: \n",
      "loss 3.699690103530884 of batch 99: \n",
      "loss 3.730940103530884 of batch 100: \n",
      "loss 3.574690103530884 of batch 101: \n",
      "loss 3.699690103530884 of batch 102: \n",
      "loss 3.637190103530884 of batch 103: \n",
      "loss 3.637190103530884 of batch 104: \n",
      "loss 3.668440103530884 of batch 105: \n",
      "loss 3.699690103530884 of batch 106: \n",
      "loss 3.605940103530884 of batch 107: \n",
      "loss 3.699690103530884 of batch 108: \n",
      "loss 3.637190103530884 of batch 109: \n",
      "loss 3.637190103530884 of batch 110: \n",
      "loss 3.605940103530884 of batch 111: \n",
      "loss 3.605940103530884 of batch 112: \n",
      "loss 3.668440103530884 of batch 113: \n",
      "loss 3.605940103530884 of batch 114: \n",
      "loss 3.605940103530884 of batch 115: \n",
      "loss 3.668440103530884 of batch 116: \n",
      "loss 3.668440103530884 of batch 117: \n",
      "loss 3.543440103530884 of batch 118: \n",
      "loss 3.668440103530884 of batch 119: \n",
      "loss 3.668440103530884 of batch 120: \n",
      "loss 3.668440103530884 of batch 121: \n",
      "loss 3.699690103530884 of batch 122: \n",
      "loss 3.668440103530884 of batch 123: \n",
      "loss 3.574690103530884 of batch 124: \n",
      "loss 3.512190103530884 of batch 125: \n",
      "loss 3.637190103530884 of batch 126: \n",
      "loss 3.605940103530884 of batch 127: \n",
      "loss 3.637190103530884 of batch 128: \n",
      "loss 3.699690103530884 of batch 129: \n",
      "loss 3.637190103530884 of batch 130: \n",
      "loss 3.574690103530884 of batch 131: \n",
      "loss 3.637190103530884 of batch 132: \n",
      "loss 3.605940103530884 of batch 133: \n",
      "loss 3.605940103530884 of batch 134: \n",
      "loss 3.699690103530884 of batch 135: \n",
      "loss 3.668440103530884 of batch 136: \n",
      "loss 3.574690103530884 of batch 137: \n",
      "loss 3.637190103530884 of batch 138: \n",
      "loss 3.699690103530884 of batch 139: \n",
      "loss 3.668440103530884 of batch 140: \n",
      "loss 3.699690103530884 of batch 141: \n",
      "loss 3.668440103530884 of batch 142: \n",
      "loss 3.699690103530884 of batch 143: \n",
      "loss 3.730940103530884 of batch 144: \n",
      "loss 3.637190103530884 of batch 145: \n",
      "loss 3.668440103530884 of batch 146: \n",
      "loss 3.668440103530884 of batch 147: \n",
      "loss 3.668440103530884 of batch 148: \n",
      "loss 3.637190103530884 of batch 149: \n",
      "loss 3.543440103530884 of batch 150: \n",
      "loss 3.699690103530884 of batch 151: \n",
      "loss 3.699690103530884 of batch 152: \n",
      "loss 3.699690103530884 of batch 153: \n",
      "loss 3.668440103530884 of batch 154: \n",
      "loss 3.512190103530884 of batch 155: \n",
      "loss 3.668440103530884 of batch 156: \n",
      "loss 3.699690103530884 of batch 157: \n",
      "loss 3.699690103530884 of batch 158: \n",
      "loss 3.637190103530884 of batch 159: \n",
      "loss 3.637190103530884 of batch 160: \n",
      "loss 3.637190103530884 of batch 161: \n",
      "loss 3.730940103530884 of batch 162: \n",
      "loss 3.543440103530884 of batch 163: \n",
      "loss 3.668440103530884 of batch 164: \n",
      "loss 3.699690103530884 of batch 165: \n",
      "loss 3.605940103530884 of batch 166: \n",
      "loss 3.637190103530884 of batch 167: \n",
      "loss 3.543440103530884 of batch 168: \n",
      "loss 3.637190103530884 of batch 169: \n",
      "loss 3.605940103530884 of batch 170: \n",
      "loss 3.637190103530884 of batch 171: \n",
      "loss 3.543440103530884 of batch 172: \n",
      "loss 3.668440103530884 of batch 173: \n",
      "loss 3.730940103530884 of batch 174: \n",
      "loss 3.668440103530884 of batch 175: \n",
      "loss 3.605940103530884 of batch 176: \n",
      "loss 3.668440103530884 of batch 177: \n",
      "loss 3.605940103530884 of batch 178: \n",
      "loss 3.668440103530884 of batch 179: \n",
      "loss 3.574690103530884 of batch 180: \n",
      "loss 3.668440103530884 of batch 181: \n",
      "loss 3.668440103530884 of batch 182: \n",
      "loss 3.668440103530884 of batch 183: \n",
      "loss 3.637190103530884 of batch 184: \n",
      "loss 3.668440103530884 of batch 185: \n",
      "loss 3.637190103530884 of batch 186: \n",
      "loss 3.637190103530884 of batch 187: \n",
      "loss 3.699690103530884 of batch 188: \n",
      "loss 3.637190103530884 of batch 189: \n",
      "loss 3.668440103530884 of batch 190: \n",
      "loss 3.668440103530884 of batch 191: \n",
      "loss 3.668440103530884 of batch 192: \n",
      "loss 3.668440103530884 of batch 193: \n",
      "loss 3.668440103530884 of batch 194: \n",
      "loss 3.637190103530884 of batch 195: \n",
      "loss 3.699690103530884 of batch 196: \n",
      "loss 3.574690103530884 of batch 197: \n",
      "loss 3.637190103530884 of batch 198: \n",
      "loss 3.699690103530884 of batch 199: \n",
      "loss 3.699690103530884 of batch 200: \n",
      "loss 3.668440103530884 of batch 201: \n",
      "loss 3.637190103530884 of batch 202: \n",
      "loss 3.668440103530884 of batch 203: \n",
      "loss 3.637190103530884 of batch 204: \n",
      "loss 3.605940103530884 of batch 205: \n",
      "loss 3.668440103530884 of batch 206: \n",
      "loss 3.543440103530884 of batch 207: \n",
      "loss 3.605940103530884 of batch 208: \n",
      "loss 3.637190103530884 of batch 209: \n",
      "loss 3.637190103530884 of batch 210: \n",
      "loss 3.574690103530884 of batch 211: \n",
      "loss 3.637190103530884 of batch 212: \n",
      "loss 3.574690103530884 of batch 213: \n",
      "loss 3.699690103530884 of batch 214: \n",
      "loss 3.668440103530884 of batch 215: \n",
      "loss 3.637190103530884 of batch 216: \n",
      "loss 3.668440103530884 of batch 217: \n",
      "loss 3.605940103530884 of batch 218: \n",
      "loss 3.637190103530884 of batch 219: \n",
      "loss 3.637190103530884 of batch 220: \n",
      "loss 3.637190103530884 of batch 221: \n",
      "loss 3.605940103530884 of batch 222: \n",
      "loss 3.605940103530884 of batch 223: \n",
      "loss 3.668440103530884 of batch 224: \n",
      "loss 3.637190103530884 of batch 225: \n",
      "loss 3.699690103530884 of batch 226: \n",
      "loss 3.637190103530884 of batch 227: \n",
      "loss 3.668440103530884 of batch 228: \n",
      "loss 3.637190103530884 of batch 229: \n",
      "loss 3.605940103530884 of batch 230: \n",
      "loss 3.668440103530884 of batch 231: \n",
      "loss 3.668440103530884 of batch 232: \n",
      "loss 3.668440103530884 of batch 233: \n",
      "loss 3.637190103530884 of batch 234: \n",
      "loss 3.574690103530884 of batch 235: \n",
      "loss 3.605940103530884 of batch 236: \n",
      "loss 3.605940103530884 of batch 237: \n",
      "loss 3.637190103530884 of batch 238: \n",
      "loss 3.637190103530884 of batch 239: \n",
      "loss 3.605940103530884 of batch 240: \n",
      "loss 3.668440103530884 of batch 241: \n",
      "loss 3.574690103530884 of batch 242: \n",
      "loss 3.699690103530884 of batch 243: \n",
      "loss 3.730940103530884 of batch 244: \n",
      "loss 3.668440103530884 of batch 245: \n",
      "loss 3.574690103530884 of batch 246: \n",
      "loss 3.699690103530884 of batch 247: \n",
      "loss 3.543440103530884 of batch 248: \n",
      "loss 3.668440103530884 of batch 249: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[1;32m      3\u001b[0m     running_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      5\u001b[0m         inputs, labels\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointcloud\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat(), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mPointCloudData.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiles[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pcd_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 34\u001b[0m     pointcloud\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__preproc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointcloud\u001b[39m\u001b[38;5;124m'\u001b[39m : pointcloud,\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses[category]}\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mPointCloudData.__preproc__\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m     24\u001b[0m verts, faces\u001b[38;5;241m=\u001b[39mread_off(file)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 26\u001b[0m     pointcloud\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointcloud\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mPointSampler.__call__\u001b[0;34m(self, mesh)\u001b[0m\n\u001b[1;32m     21\u001b[0m areas\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(faces)))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(areas)):\n\u001b[0;32m---> 23\u001b[0m     areas[i]\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriangle_area\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mverts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mverts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m sampled_faces\u001b[38;5;241m=\u001b[39m(random\u001b[38;5;241m.\u001b[39mchoices(faces,\n\u001b[1;32m     28\u001b[0m                              weights\u001b[38;5;241m=\u001b[39mareas,\n\u001b[1;32m     29\u001b[0m                              cum_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m                              k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size))\n\u001b[1;32m     32\u001b[0m sampled_points\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size, \u001b[38;5;241m3\u001b[39m))\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mPointSampler.triangle_area\u001b[0;34m(self, pt1, pt2, pt3)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtriangle_area\u001b[39m(\u001b[38;5;28mself\u001b[39m, pt1, pt2, pt3):\n\u001b[0;32m----> 7\u001b[0m     side_a\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt1\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mpt2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     side_b\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(pt2\u001b[38;5;241m-\u001b[39mpt3)\n\u001b[1;32m      9\u001b[0m     side_c\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(pt3\u001b[38;5;241m-\u001b[39mpt1)\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed00c75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea771840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eacd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ca00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47459b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464f9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a539e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85644f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df73c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a49f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac9ff46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ba901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22ffbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7680feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a575a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8837cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a0162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8847ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66843a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d1317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acaf26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f1ac60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a66a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280c183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26827040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d1bb5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a15f1a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12f86254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8afbc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8881c3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3e3dc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7acd981b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83afd26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76cce346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de9f111f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dab2a365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5598c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3eb20959",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [32, 256, 3] at index 2 does not match the shape of the indexed tensor [32, 256, 16] at index 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpointnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, epochs, save)\u001b[0m\n\u001b[1;32m      6\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointcloud\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat(), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m outputs\u001b[38;5;241m=\u001b[39m \u001b[43mpointnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mPoint_Transformer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m     norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m## Set Abstraction with MSG\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m l1_xyz, l1_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m l2_xyz, l2_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa2(l1_xyz, l1_points)\n\u001b[1;32m     97\u001b[0m global_feat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([l2_xyz, l2_points], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mPointNetSetAbstractionMsg.forward\u001b[0;34m(self, xyz, points)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, radius \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradius_list):\n\u001b[1;32m     38\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsample_list[i]\n\u001b[0;32m---> 39\u001b[0m     group_idx \u001b[38;5;241m=\u001b[39m \u001b[43mquery_ball_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_xyz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     grouped_xyz \u001b[38;5;241m=\u001b[39m index_points(xyz, group_idx)\n\u001b[1;32m     41\u001b[0m     grouped_xyz \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m new_xyz\u001b[38;5;241m.\u001b[39mview(B, S, \u001b[38;5;241m1\u001b[39m, C)\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mquery_ball_point\u001b[0;34m(radius, nsample, xyz, new_xyz)\u001b[0m\n\u001b[1;32m     18\u001b[0m group_first \u001b[38;5;241m=\u001b[39m group_idx[:, :, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mview(B, S, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, nsample])\n\u001b[1;32m     19\u001b[0m mask \u001b[38;5;241m=\u001b[39m group_idx \u001b[38;5;241m==\u001b[39m N\n\u001b[0;32m---> 20\u001b[0m group_idx[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_first\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m group_idx\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [32, 256, 3] at index 2 does not match the shape of the indexed tensor [32, 256, 16] at index 2"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5350bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b927ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6794, 0.6302, 0.2393],\n",
      "         [0.7705, 0.6448, 0.5285],\n",
      "         [0.1703, 0.6312, 0.5203],\n",
      "         [0.7421, 0.0197, 0.5319],\n",
      "         [0.7266, 0.7388, 0.7423],\n",
      "         [0.0330, 0.8191, 0.6201],\n",
      "         [0.8280, 0.1459, 0.6869],\n",
      "         [0.4378, 0.5661, 0.5191],\n",
      "         [0.9522, 0.1850, 0.9113],\n",
      "         [0.7879, 0.3846, 0.5760]],\n",
      "\n",
      "        [[0.4122, 0.2750, 0.2543],\n",
      "         [0.9969, 0.3531, 0.8177],\n",
      "         [0.6538, 0.9346, 0.4969],\n",
      "         [0.7928, 0.5726, 0.6629],\n",
      "         [0.6816, 0.5527, 0.6366],\n",
      "         [0.8280, 0.5558, 0.8445],\n",
      "         [0.0375, 0.3176, 0.3728],\n",
      "         [0.4986, 0.4665, 0.2881],\n",
      "         [0.7322, 0.2450, 0.6097],\n",
      "         [0.7538, 0.0550, 0.8272]],\n",
      "\n",
      "        [[0.3140, 0.7076, 0.8817],\n",
      "         [0.7900, 0.9898, 0.1162],\n",
      "         [0.8440, 0.6232, 0.4816],\n",
      "         [0.9902, 0.2445, 0.9466],\n",
      "         [0.3084, 0.1920, 0.8627],\n",
      "         [0.4768, 0.9245, 0.8775],\n",
      "         [0.9604, 0.9177, 0.2915],\n",
      "         [0.4730, 0.6404, 0.1862],\n",
      "         [0.1363, 0.5470, 0.0955],\n",
      "         [0.2995, 0.4411, 0.9508]],\n",
      "\n",
      "        [[0.6408, 0.1664, 0.4323],\n",
      "         [0.7093, 0.2054, 0.1226],\n",
      "         [0.8074, 0.9498, 0.7413],\n",
      "         [0.4487, 0.2476, 0.9155],\n",
      "         [0.9703, 0.2498, 0.0106],\n",
      "         [0.1414, 0.2028, 0.2990],\n",
      "         [0.9911, 0.9071, 0.3094],\n",
      "         [0.8519, 0.2631, 0.7295],\n",
      "         [0.9188, 0.5457, 0.6530],\n",
      "         [0.5332, 0.5120, 0.8764]],\n",
      "\n",
      "        [[0.9134, 0.8275, 0.2506],\n",
      "         [0.9077, 0.1099, 0.7899],\n",
      "         [0.8925, 0.4644, 0.2271],\n",
      "         [0.4008, 0.9734, 0.4496],\n",
      "         [0.1651, 0.1885, 0.4989],\n",
      "         [0.1591, 0.9738, 0.0224],\n",
      "         [0.3188, 0.4348, 0.6180],\n",
      "         [0.6898, 0.8856, 0.9653],\n",
      "         [0.3882, 0.0761, 0.9242],\n",
      "         [0.9989, 0.4769, 0.4305]],\n",
      "\n",
      "        [[0.8502, 0.9549, 0.5088],\n",
      "         [0.1331, 0.4591, 0.5353],\n",
      "         [0.0345, 0.2617, 0.9837],\n",
      "         [0.4188, 0.8233, 0.1626],\n",
      "         [0.6092, 0.4195, 0.1834],\n",
      "         [0.1322, 0.9558, 0.9881],\n",
      "         [0.2892, 0.7729, 0.9848],\n",
      "         [0.3603, 0.5746, 0.2322],\n",
      "         [0.6011, 0.5370, 0.0668],\n",
      "         [0.4901, 0.9325, 0.1861]]])\n",
      "tensor([[7, 8, 5, 3, 4],\n",
      "        [6, 1, 2, 7, 4],\n",
      "        [1, 4, 8, 5, 3],\n",
      "        [2, 5, 4, 3, 0],\n",
      "        [8, 5, 2, 7, 1],\n",
      "        [4, 5, 2, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c892c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599d718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb233b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1746bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404ce8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d47ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79de9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ece483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf6085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
